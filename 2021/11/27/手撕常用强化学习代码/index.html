<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yichuyang.com","root":"/blog/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="DQN 损失函数： 梯度： 算法：   Bellman equation describing the optimal action-value function, .   It’s given by  mean-squared Bellman error (MSBE) function, which tells us roughly how closely  comes to satisfyi">
<meta property="og:type" content="article">
<meta property="og:title" content="手撕常用强化学习代码">
<meta property="og:url" content="https://yichuyang.com/blog/2021/11/27/%E6%89%8B%E6%92%95%E5%B8%B8%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/index.html">
<meta property="og:site_name" content="YYC的个人空间">
<meta property="og:description" content="DQN 损失函数： 梯度： 算法：   Bellman equation describing the optimal action-value function, .   It’s given by  mean-squared Bellman error (MSBE) function, which tells us roughly how closely  comes to satisfyi">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127235059145.png">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225236029.png">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225156370.png">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225206700.png">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225437092.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/cbed396f671d6fb54f6df5c044b82ab3f052d63e.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/3a8b6ce0d6c0b68744b5724403f5d70ed5cda5db.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/c25464faf1bf4928960905461cbbabe1d2441cb2.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/31dda6ac0678255c4e192dd6fae4f7ed3c7cd91b.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128163448569.png">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128163513253.png">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128163245890.png">
<meta property="og:image" content="c:/Users/yichu/AppData/Roaming/Typora/typora-user-images/image-20211128163258450.png">
<meta property="og:image" content="c:/Users/yichu/AppData/Roaming/Typora/typora-user-images/image-20211128163306443.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/ada1266646d71c941e77e3fd41bba9d92d06b7c2.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128004331312.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/6a71f04b65d9524fb656715cda85d7540a9ddf9f.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/ce5edddd490112350f4bd555d9390e0e845f754a.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/23edf1f72f63a4729c40371c1481a36549a0b713.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/0837b005b194415b2b922e42be1df8601b552857.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/6a71f04b65d9524fb656715cda85d7540a9ddf9f.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/d8bb9f337fa712549e0428223df820773aa1169d.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/ae8edab1e9c727bed15e54d4dda492382538b5fe.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/88396050a58384b85dfaa6fce02cf39d98c78c4b.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/78a651e0ce4979bd3e17198594ad952ac20b9b45.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/a485f77ef16acbb27539cdfe8286cd6029ccfd26.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/7cdaa039734ec1d09adcc3e4dc351085823085cf.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/69c9dcbe2fe1c669a1b2cb3a312a479cdfcb27a1.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/e990f7ff0230a8fa93cf1242ea0d49fdf63d05d7.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/03cabd66ab79d8c17e36fc4247bb46fe0c6dcbfc.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128005202175.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/96a52e61318720522e040e433c938ee829d54506.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/3ffe1da701d78dd473975ebd2f875807611f7713.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/99621d5bcaccd056d6ca3aeb48a27bf8cc0e640c.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/dd41a29292af3bc58c0c76bc7dba82a7355bf929.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/39f524858866b80e627840ba77a54360e3bac55e.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128010316710.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/d417987803ca9f61ac60741880a748129bd66dde.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/a50d5d2b71fa30f115adf18b0bb1354f967b064a.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/4421120861d55302d76c7e2fd7cc5b2da7aea320.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/a325c9e05fa2ccce85eb2384ca00b4888d1c7824.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/6923cb2043e84ea05d3eddbb7436c60659243cb9.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/521198ffdba43bf32186f95801549cd1502b76c7.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/cc4e3565d839e63e871a1cf7e3ce5e95bb616b29.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128015259509.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/a325c9e05fa2ccce85eb2384ca00b4888d1c7824.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/76a319586cd215c8f2075b938fc6f6e07c81714b.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/a5132668c0af8733656505c5fb6c1dff4a7907a1.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/8efd61c40551db4eddb3f780d2804cac34c8ae52.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/70901eaea34c31e03bb878d7a710a33cb75d1143.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/7d5c18f49a242cc3eec554f717fe4f3bfc119bab.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/cd73726a8a3845ade467aed57714912f868f6b36.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/8795d42bd263dcbe55d123e7466b2dd5091490a7.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/9ed1a541005a48d51b624c3b329897064ec2c065.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128020516543.png">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/ea07a4204f1f53321f76d9c7e348199f0d707db1.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/4204ba416334e663d7bd7c6457d737ba3cbbfe46.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/bf6bcb1745aeab36cdc185e9f75bbfd3998352ce.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/ea07a4204f1f53321f76d9c7e348199f0d707db1.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/4204ba416334e663d7bd7c6457d737ba3cbbfe46.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/1bf89d5228652e14d82657fe9f1499b136f54094.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/b86bf499707114c8789946df649871c5b9185b9d.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/fbed8ae629f7512710c5352ca50e8f629d7f34e4.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/2bbd8ab5668fe92f59056f58c9f75a01c929e37d.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/46d0852616c131f3d5aa2d1798328141904a764d.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/2bbd8ab5668fe92f59056f58c9f75a01c929e37d.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/8010672f1e8269ce985f901728e7224faa07731e.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/0bd81fc5d1cb03a33d6477f5ff10ed879ea393ec.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/fc03ff9e9f818fb31b7724907e2b43d5101d2ab8.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/a81303323c25fc13cd0652ca46d7596276e5cb7e.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/5ff58df73caef07f6309a1460fe57b1c34e3b374.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/e57f13375048b8f7343f9066b6553bc282afa326.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/dac3ddc2ea35e8233b8bc0a905273712793ab1cb.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/5713f9f99ea3532e3cbde89eac91328eb8549409.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/9c39112fd52e66e3062f93c502ade0eb9381d957.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/8795d42bd263dcbe55d123e7466b2dd5091490a7.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/e5d14ed1b7128d64d43af73b7d0b189c6afda8ec.svg">
<meta property="og:image" content="https://spinningup.openai.com/en/latest/_images/math/bdbe4cabbba4687b310d99e8fa67ed314339bd31.svg">
<meta property="og:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128022803736.png">
<meta property="article:published_time" content="2021-11-28T00:53:44.000Z">
<meta property="article:modified_time" content="2021-11-28T23:28:48.178Z">
<meta property="article:author" content="YYC">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127235059145.png">

<link rel="canonical" href="https://yichuyang.com/blog/2021/11/27/%E6%89%8B%E6%92%95%E5%B8%B8%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>手撕常用强化学习代码 | YYC的个人空间</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">YYC的个人空间</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-top">

    <a href="/blog/top/" rel="section"><i class="fas fa-temperature-high fa-fw"></i>热门文章</a>

  </li>
        <li class="menu-item menu-item-resume">

    <a href="https://yichuyang.com/" rel="section"><i class="fa fa-user fa-fw"></i>简历</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/yangyichu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yichuyang.com/blog/2021/11/27/%E6%89%8B%E6%92%95%E5%B8%B8%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="YYC">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YYC的个人空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          手撕常用强化学习代码
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-11-27 19:53:44" itemprop="dateCreated datePublished" datetime="2021-11-27T19:53:44-05:00">2021-11-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-28 18:28:48" itemprop="dateModified" datetime="2021-11-28T18:28:48-05:00">2021-11-28</time>
              </span>

          
            <span id="/blog/2021/11/27/%E6%89%8B%E6%92%95%E5%B8%B8%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/" class="post-meta-item leancloud_visitors" data-flag-title="手撕常用强化学习代码" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/blog/2021/11/27/%E6%89%8B%E6%92%95%E5%B8%B8%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/blog/2021/11/27/%E6%89%8B%E6%92%95%E5%B8%B8%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127235059145.png" alt="image-20211127235059145"></p>
<h2 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.5602"><strong>DQN</strong></a></h2><p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225236029.png" alt="image-20211127225236029"></p>
<p>损失函数：<img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225156370.png" alt="image-20211127225156370"></p>
<p>梯度：<img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225206700.png" alt="image-20211127225206700"></p>
<p>算法：</p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211127225437092.png" alt="image-20211127225437092"></p>
<p> Bellman equation describing the optimal action-value function, <img src="https://spinningup.openai.com/en/latest/_images/math/cbed396f671d6fb54f6df5c044b82ab3f052d63e.svg" alt="x">. </p>
<p> It’s given by</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/3a8b6ce0d6c0b68744b5724403f5d70ed5cda5db.svg" alt="x"></p>
<p><strong>mean-squared Bellman error (MSBE)</strong> function, which tells us roughly how closely <img src="https://spinningup.openai.com/en/latest/_images/math/c25464faf1bf4928960905461cbbabe1d2441cb2.svg" alt="x"> comes to satisfying the Bellman equation:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/31dda6ac0678255c4e192dd6fae4f7ed3c7cd91b.svg" alt="x"></p>
<p>主要改进：    </p>
<ol>
<li><p>Experience Replay: 储存加随机采样回放，降低样本间相关性，降低方差</p>
</li>
<li><p>Target Network: <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="32.155ex" height="2.452ex" role="img" focusable="false" viewBox="0 -833.9 14212.6 1083.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(575.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(1631.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2020.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2693.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(3694,0)"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="msub" transform="translate(4237,0)"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(824,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mi" transform="translate(5366.3,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5895.3,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6346.3,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(6823.3,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(7289.3,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(7872.5,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(8872.7,0)"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(824,-150) scale(0.707)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g></g><g data-mml-node="mi" transform="translate(10050.1,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(10516.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(11092.1,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(11621.1,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(12106.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(12451.1,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(12936.1,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msup" transform="translate(13387.1,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
</li>
</ol>
<span id="more"></span>

<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128163448569.png" alt="image-20211128163448569"></p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128163513253.png" alt="image-20211128163513253"></p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128163245890.png" alt="image-20211128163245890"></p>
<h3 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h3><p><img src="C:\Users\yichu\AppData\Roaming\Typora\typora-user-images\image-20211128163258450.png" alt="image-20211128163258450"></p>
<h3 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h3><p><img src="C:\Users\yichu\AppData\Roaming\Typora\typora-user-images\image-20211128163306443.png" alt="image-20211128163306443"></p>
<h2 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h2><h3 id="Vanilla-PG"><a href="#Vanilla-PG" class="headerlink" title="Vanilla PG"></a>Vanilla PG</h3><p><img src="https://spinningup.openai.com/en/latest/_images/math/ada1266646d71c941e77e3fd41bba9d92d06b7c2.svg" alt="x"></p>
<p>Advantage Function: A=V-R</p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128004331312.png" alt="image-20211128004331312"></p>
<p>from <a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/algorithms/vpg.html#pseudocode">spinningup</a>.</p>
<h3 id="TRPO"><a href="#TRPO" class="headerlink" title="TRPO"></a>TRPO</h3><p>Let <img src="https://spinningup.openai.com/en/latest/_images/math/6a71f04b65d9524fb656715cda85d7540a9ddf9f.svg" alt="x"> denote a policy with parameters <img src="https://spinningup.openai.com/en/latest/_images/math/ce5edddd490112350f4bd555d9390e0e845f754a.svg" alt="x">. The theoretical TRPO update is:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/23edf1f72f63a4729c40371c1481a36549a0b713.svg" alt="x"></p>
<p>where <img src="https://spinningup.openai.com/en/latest/_images/math/0837b005b194415b2b922e42be1df8601b552857.svg" alt="x"> is the <em>surrogate advantage</em>, a measure of how policy <img src="https://spinningup.openai.com/en/latest/_images/math/6a71f04b65d9524fb656715cda85d7540a9ddf9f.svg" alt="x"> performs relative to the old policy <img src="https://spinningup.openai.com/en/latest/_images/math/d8bb9f337fa712549e0428223df820773aa1169d.svg" alt="x"> using data from the old policy:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/ae8edab1e9c727bed15e54d4dda492382538b5fe.svg" alt="x"></p>
<p>and <img src="https://spinningup.openai.com/en/latest/_images/math/88396050a58384b85dfaa6fce02cf39d98c78c4b.svg" alt="x"> is an average KL-divergence between policies across states visited by the old policy:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/78a651e0ce4979bd3e17198594ad952ac20b9b45.svg" alt="x"></p>
<p> We Taylor expand the objective and constraint to leading order around <img src="https://spinningup.openai.com/en/latest/_images/math/a485f77ef16acbb27539cdfe8286cd6029ccfd26.svg" alt="x">:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/7cdaa039734ec1d09adcc3e4dc351085823085cf.svg" alt="{x"></p>
<p>resulting in an approximate optimization problem,</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/69c9dcbe2fe1c669a1b2cb3a312a479cdfcb27a1.svg" alt="x"></p>
<p>This approximate problem can be analytically solved by the methods of Lagrangian duality [x]](<a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/algorithms/trpo.html#id2">https://spinningup.openai.com/en/latest/algorithms/trpo.html#id2</a>), yielding the solution:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/e990f7ff0230a8fa93cf1242ea0d49fdf63d05d7.svg" alt="x"></p>
<p>If we were to stop here, and just use this final result, the algorithm would be exactly calculating the <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf">Natural Policy Gradient</a>. TRPO adds a modification to this update rule: a backtracking line search,</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/03cabd66ab79d8c17e36fc4247bb46fe0c6dcbfc.svg" alt="x"><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128005202175.png" alt="image-20211128005202175"></p>
<h3 id="PPO-clipped"><a href="#PPO-clipped" class="headerlink" title="PPO(clipped)"></a>PPO(clipped)</h3><p><img src="https://spinningup.openai.com/en/latest/_images/math/96a52e61318720522e040e433c938ee829d54506.svg" alt="x"></p>
<p>typically taking multiple steps of (usually minibatch) SGD to maximize the objective. Here <img src="https://spinningup.openai.com/en/latest/_images/math/3ffe1da701d78dd473975ebd2f875807611f7713.svg" alt="L"> is given by</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/99621d5bcaccd056d6ca3aeb48a27bf8cc0e640c.svg" alt="x"></p>
<p>simpler version:          <img src="https://spinningup.openai.com/en/latest/_images/math/dd41a29292af3bc58c0c76bc7dba82a7355bf929.svg" alt="x"></p>
<p>where:                            <img src="https://spinningup.openai.com/en/latest/_images/math/39f524858866b80e627840ba77a54360e3bac55e.svg" alt="x"><em>the new policy does not benefit by going far away from the old policy</em></p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128010316710.png" alt="x"></p>
<h3 id="DDPG"><a href="#DDPG" class="headerlink" title="DDPG"></a>DDPG</h3><h4 id="The-Q-Learning-Side-of-DDPG"><a href="#The-Q-Learning-Side-of-DDPG" class="headerlink" title="The Q-Learning Side of DDPG"></a><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/algorithms/ddpg.html#id5">The Q-Learning Side of DDPG</a></h4><p>polyak averaging:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/d417987803ca9f61ac60741880a748129bd66dde.svg" alt="x"></p>
<p>DDPG deals with computing the maximum over actions in the target in <strong>continuous action spaces</strong> by using a <strong>target policy network</strong> to compute an action which approximately maximizes <img src="https://spinningup.openai.com/en/latest/_images/math/a50d5d2b71fa30f115adf18b0bb1354f967b064a.svg">.</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/4421120861d55302d76c7e2fd7cc5b2da7aea320.svg" alt="x"></p>
<p>where <img src="https://spinningup.openai.com/en/latest/_images/math/a325c9e05fa2ccce85eb2384ca00b4888d1c7824.svg"> is the target policy.</p>
<h4 id="The-Policy-Learning-Side-of-DDPG"><a href="#The-Policy-Learning-Side-of-DDPG" class="headerlink" title="The Policy Learning Side of DDPG"></a><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/algorithms/ddpg.html#id6">The Policy Learning Side of DDPG</a></h4><p>We want to learn a deterministic policy <img src="https://spinningup.openai.com/en/latest/_images/math/6923cb2043e84ea05d3eddbb7436c60659243cb9.svg"> which gives the action that maximizes <img src="https://spinningup.openai.com/en/latest/_images/math/521198ffdba43bf32186f95801549cd1502b76c7.svg">.</p>
<p>perform gradient ascent (with respect to policy parameters only) to solve: <img src="https://spinningup.openai.com/en/latest/_images/math/cc4e3565d839e63e871a1cf7e3ce5e95bb616b29.svg" alt="x"></p>
<p>Note that the Q-function parameters are treated as constants here.</p>
<p>DDPG trains a deterministic policy in an off-policy way. Because the policy is deterministic, if the agent were to explore on-policy, in the beginning it would probably not try a wide enough variety of actions to find useful learning signals. To make DDPG policies explore better, we add noise to their actions at training time.</p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128015259509.png" alt="image-20211128015259509"></p>
<h3 id="TD3"><a href="#TD3" class="headerlink" title="TD3"></a>TD3</h3><p>A common failure mode for DDPG is that the learned Q-function begins to dramatically overestimate Q-values, which then leads to the policy breaking, because it exploits the errors in the Q-function. </p>
<p><strong>Trick One: Clipped Double-Q Learning.</strong> TD3 learns <em>two</em> Q-functions instead of one (hence “twin”), and uses the smaller of the two Q-values to form the targets in the Bellman error loss functions.</p>
<p><strong>Trick Two: “Delayed” Policy Updates.</strong> TD3 updates the policy (and target networks) less frequently than the Q-function. The paper recommends one policy update for every two Q-function updates.</p>
<p><strong>Trick Three: Target Policy Smoothing.</strong> TD3 adds noise to the target action, to make it harder for the policy to exploit Q-function errors by smoothing out Q along changes in action.</p>
<p><strong>target policy smoothing</strong>. Actions used to form the Q-learning target are based on the target policy, <img src="https://spinningup.openai.com/en/latest/_images/math/a325c9e05fa2ccce85eb2384ca00b4888d1c7824.svg" alt="x">, but with clipped noise added on each dimension of the action. After adding the clipped noise, the target action is then clipped to lie in the valid action range (all valid actions, <img src="https://spinningup.openai.com/en/latest/_images/math/76a319586cd215c8f2075b938fc6f6e07c81714b.svg" alt="a">, satisfy <img src="https://spinningup.openai.com/en/latest/_images/math/a5132668c0af8733656505c5fb6c1dff4a7907a1.svg">). The target actions are thus:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/8efd61c40551db4eddb3f780d2804cac34c8ae52.svg" alt="x"></p>
<p><strong>clipped double-Q learning</strong>. Both Q-functions use a single target, calculated using whichever of the two Q-functions gives a smaller target value:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/70901eaea34c31e03bb878d7a710a33cb75d1143.svg"></p>
<p>and then both are learned by regressing to this target:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/7d5c18f49a242cc3eec554f717fe4f3bfc119bab.svg"></p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/cd73726a8a3845ade467aed57714912f868f6b36.svg"></p>
<p>Using the smaller Q-value for the target, and regressing towards that, helps fend off overestimation in the Q-function.</p>
<p>Lastly: the policy is learned just by maximizing <img src="https://spinningup.openai.com/en/latest/_images/math/8795d42bd263dcbe55d123e7466b2dd5091490a7.svg">:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/9ed1a541005a48d51b624c3b329897064ec2c065.svg"></p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128020516543.png" alt="image-20211128020516543"></p>
<h3 id="SAC"><a href="#SAC" class="headerlink" title="SAC"></a>SAC</h3><p>A central feature of SAC is <strong>entropy regularization.</strong> The policy is trained to maximize a trade-off between expected return and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">entropy</a>, a measure of randomness in the policy.</p>
<p><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/algorithms/sac.html#id6">Entropy-Regularized Reinforcement Learning</a></p>
<p>Let <img src="https://spinningup.openai.com/en/latest/_images/math/ea07a4204f1f53321f76d9c7e348199f0d707db1.svg" alt="x"> be a random variable with probability mass or density function <img src="https://spinningup.openai.com/en/latest/_images/math/4204ba416334e663d7bd7c6457d737ba3cbbfe46.svg" alt="P">. The entropy <img src="https://spinningup.openai.com/en/latest/_images/math/bf6bcb1745aeab36cdc185e9f75bbfd3998352ce.svg" alt="H"> of <img src="https://spinningup.openai.com/en/latest/_images/math/ea07a4204f1f53321f76d9c7e348199f0d707db1.svg" alt="x"> is computed from its distribution <img src="https://spinningup.openai.com/en/latest/_images/math/4204ba416334e663d7bd7c6457d737ba3cbbfe46.svg" alt="P"> according to</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/1bf89d5228652e14d82657fe9f1499b136f54094.svg"></p>
<p>In entropy-regularized reinforcement learning, the agent gets a bonus reward at each time step proportional to the entropy of the policy at that timestep. This changes <a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#the-rl-problem">the RL problem</a> to:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/b86bf499707114c8789946df649871c5b9185b9d.svg"></p>
<p>With these definitions, <img src="https://spinningup.openai.com/en/latest/_images/math/fbed8ae629f7512710c5352ca50e8f629d7f34e4.svg"> and <img src="https://spinningup.openai.com/en/latest/_images/math/2bbd8ab5668fe92f59056f58c9f75a01c929e37d.svg"> are connected by:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/46d0852616c131f3d5aa2d1798328141904a764d.svg"></p>
<p>and the Bellman equation for <img src="https://spinningup.openai.com/en/latest/_images/math/2bbd8ab5668fe92f59056f58c9f75a01c929e37d.svg"> is</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/8010672f1e8269ce985f901728e7224faa07731e.svg"></p>
<p> the loss functions for the Q-networks in SAC are:</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/0bd81fc5d1cb03a33d6477f5ff10ed879ea393ec.svg"></p>
<p>where the target is given by</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/fc03ff9e9f818fb31b7724907e2b43d5101d2ab8.svg"></p>
<p><strong>Learning the Policy.</strong> The policy should, in each state, act to maximize the expected future return plus expected future entropy. That is, it should maximize <img src="https://spinningup.openai.com/en/latest/_images/math/a81303323c25fc13cd0652ca46d7596276e5cb7e.svg">, which we expand out into</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/5ff58df73caef07f6309a1460fe57b1c34e3b374.svg"></p>
<p>The way we optimize the policy makes use of the <strong>reparameterization trick</strong>, in which a sample from <img src="https://spinningup.openai.com/en/latest/_images/math/e57f13375048b8f7343f9066b6553bc282afa326.svg"> is drawn by computing a deterministic function of state, policy parameters, and independent noise. To illustrate: following the authors of the SAC paper, we use a squashed Gaussian policy, which means that samples are obtained according to</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/dac3ddc2ea35e8233b8bc0a905273712793ab1cb.svg"></p>
<p>The reparameterization trick allows us to rewrite the expectation over actions (which contains a pain point: the distribution depends on the policy parameters) into an expectation over noise (which removes the pain point: the distribution now has no dependence on parameters):</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/5713f9f99ea3532e3cbde89eac91328eb8549409.svg"></p>
<p>To get the policy loss, the final step is that we need to substitute <img src="https://spinningup.openai.com/en/latest/_images/math/9c39112fd52e66e3062f93c502ade0eb9381d957.svg"> with one of our function approximators. Unlike in TD3, which uses <img src="https://spinningup.openai.com/en/latest/_images/math/8795d42bd263dcbe55d123e7466b2dd5091490a7.svg"> (just the first Q approximator), SAC uses <img src="https://spinningup.openai.com/en/latest/_images/math/e5d14ed1b7128d64d43af73b7d0b189c6afda8ec.svg"> (the minimum of the two Q approximators). The policy is thus optimized according to</p>
<p><img src="https://spinningup.openai.com/en/latest/_images/math/bdbe4cabbba4687b310d99e8fa67ed314339bd31.svg"></p>
<p>which is almost the same as the DDPG and TD3 policy optimization, except for the min-double-Q trick, the stochasticity, and the entropy term.</p>
<p><img src="https://yichu-1305057184.cos.ap-shanghai.myqcloud.com/typora/image-20211128022803736.png" alt="image-20211128022803736"></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2021/11/27/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0loss%E4%B8%AD%E7%9A%84log%E6%98%AF%E6%80%8E%E4%B9%88%E6%9D%A5%E7%9A%84%EF%BC%9F/" rel="prev" title="强化学习loss中的log是怎么来的？">
      <i class="fa fa-chevron-left"></i> 强化学习loss中的log是怎么来的？
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2021/11/27/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E6%94%B6%E9%9B%86/" rel="next" title="强化学习面试题收集">
      强化学习面试题收集 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#DQN"><span class="nav-number">1.</span> <span class="nav-text">DQN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Double-DQN"><span class="nav-number">1.1.</span> <span class="nav-text">Double DQN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dueling-DQN"><span class="nav-number">1.2.</span> <span class="nav-text">Dueling DQN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Policy-Gradient"><span class="nav-number">2.</span> <span class="nav-text">Policy Gradient</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Vanilla-PG"><span class="nav-number">2.1.</span> <span class="nav-text">Vanilla PG</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TRPO"><span class="nav-number">2.2.</span> <span class="nav-text">TRPO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PPO-clipped"><span class="nav-number">2.3.</span> <span class="nav-text">PPO(clipped)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DDPG"><span class="nav-number">2.4.</span> <span class="nav-text">DDPG</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Q-Learning-Side-of-DDPG"><span class="nav-number">2.4.1.</span> <span class="nav-text">The Q-Learning Side of DDPG</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Policy-Learning-Side-of-DDPG"><span class="nav-number">2.4.2.</span> <span class="nav-text">The Policy Learning Side of DDPG</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TD3"><span class="nav-number">2.5.</span> <span class="nav-text">TD3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SAC"><span class="nav-number">2.6.</span> <span class="nav-text">SAC</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YYC"
      src="/blog/images/avatar.gif">
  <p class="site-author-name" itemprop="name">YYC</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yangyichu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yangyichu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yichu.yang@gmail.com" title="E-Mail → mailto:yichu.yang@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接&实用站点
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://yichuyang.com/" title="http:&#x2F;&#x2F;yichuyang.com">Yichu's website</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://theme-next.iissnan.com/getting-started.html" title="https:&#x2F;&#x2F;theme-next.iissnan.com&#x2F;getting-started.html" rel="noopener" target="_blank">Next doc</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://hexo.io/docs/" title="https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;" rel="noopener" target="_blank">Hexo doc</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://hyxxsfwy.github.io/2016/01/15/Hexo-Markdown-%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/" title="https:&#x2F;&#x2F;hyxxsfwy.github.io&#x2F;2016&#x2F;01&#x2F;15&#x2F;Hexo-Markdown-%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C&#x2F;" rel="noopener" target="_blank">Hexo Markdown 简明语法手册</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://hrbust-acm-team.gitbooks.io/acm-book/content/" title="https:&#x2F;&#x2F;hrbust-acm-team.gitbooks.io&#x2F;acm-book&#x2F;content&#x2F;" rel="noopener" target="_blank">ACM boo</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://spinningup.openai.com/" title="https:&#x2F;&#x2F;spinningup.openai.com&#x2F;" rel="noopener" target="_blank">openai强化学习教程</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YYC</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"NxFnkhXDj709L98MOOusCvsJ-gzGzoHsz","app_key":"XhU0D02ubqnP8WW4d39ywKDe","server_url":"leancloud.cn","security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  




  
<script src="/blog/js/local-search.js"></script>













  

  

  

  <script async src="https://yichuyang.com/blog/js/cursor/fireworks.js"></script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'NxFnkhXDj709L98MOOusCvsJ-gzGzoHsz',
      appKey     : 'XhU0D02ubqnP8WW4d39ywKDe',
      placeholder: "快来评论一下吧~",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>


<script src="/blog/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":null,"tagMode":false,"debug":false,"model":{"jsonPath":"/blog/live2dw/assets/umaru.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.8},"log":false});</script></body>
</html>
